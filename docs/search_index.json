[["index.html", "Data Management for Cancer Research About this course", " Data Management for Cancer Research 2022-03-03 About this course This course is part of a series of courses for the Informatics Technology for Cancer Research (ITCR) called the Informatics Technology for Cancer Research Education Resource. This material was created by the ITCR Training Network (ITN) which is a collaborative effort of researchers around the United States to support cancer informatics and data science training through resources, technology, and events. This initiative is funded by the following grant: National Cancer Institute (NCI) UE5 CA254170. Our courses feature tools developed by ITCR Investigators and make it easier for principal investigators, scientists, and analysts to integrate cancer informatics into their workflows. Please see our website at www.itcrtraining.org for more information. Except where otherwise indicated, the contents of this course are available for use under the Creative Commons Attribution 4.0 license. You are free to adapt and share the work, but you must give appropriate credit, provide a link to the license, and indicate if changes were made. Sample attribution: Data Management for Cancer Research by Johns Hopkins Data Science Lab (CC-BY 4.0). You can download the illustrations by clicking here. "],["introduction.html", "Chapter 1 Introduction 1.1 Motivation 1.2 Target Audience 1.3 Curriculum", " Chapter 1 Introduction 1.1 Motivation One of the key cancer informatics challenges is dealing with and managing the explosion of data from multiple sources. This course is designed to help researchers and investigators to understand the key principles of data management from an economic, privacy, security, usability and discoverability perspective. 1.2 Target Audience This course is intended for researchers (including postdocs and students) with limited to intermediate experience with informatics research. The conceptual material will also be useful for those in management roles who are collecting data and using informatics pipelines. 1.3 Curriculum The course will cover the key underlying principles and concepts in data management. It will also cover data security, data privacy, IRB and data access requests, and the ethics of good data management. The course will highlight concrete workflows for managing genomic, imaging, and clinical data. "],["data-security.html", "Chapter 2 Data Security 2.1 Data Security Strategies 2.2 Data access 2.3 Data masking 2.4 Data erasure 2.5 Data resiliency 2.6 Security in workflows", " Chapter 2 Data Security In this chapter we will discuss best practices for keeping your data safe and secure. Data security involves protecting your data from human error, as well as from cybercriminals. Precious data needs to be protected from being corrupted (rendered unusable), being deleted, being misused, and being leaked to the public when the data is sensitive or private (as is the case with much of our clinical data)(“What Is Data Security? Data Security Definition and Overview” n.d.). 2.1 Data Security Strategies There a several major strategies to achieve data security. We will cover the following 4 major categories, in part according to “What Is Data Security? Data Security Definition and Overview” (n.d.). 2.2 Data access 2.2.1 Authentication Authentication is the process of verifying identification. This goes both ways when a user attempts to use a server. Servers will check that a user (client) is who they claim to be and that they are authorized to access the information on the server. The user’s computer (client) will also check that the server is what it claims to be. Typically users will use a user name and password for the server to confirm identity, however your computer often checks a certificate from the server to confirm it’s identity (“Understanding Authentication, Authorization, and Encryption : TechWeb : Boston University” n.d.). 2.2.2 Authorization Authorization is the process of verifying that a client has permission to access a file or computing resource in a particular way, which leads us to permissions (“Understanding Authentication, Authorization, and Encryption : TechWeb : Boston University” n.d.). 2.2.3 Permissions If you use the command line, you may have noticed that files are sometimes listed with letters like so: These letters indicate the users ability to perform tasks for each file called file system permissions. In unix or unix-like systems, there are three types of users: Owner (sometimes called user) - This is the person that created the file by default Group users - groups can be created to more easily give the correct permissions for various files for a similar group of users. Other users - This is any other user who might come into access with the file There are generally 3 types of permissions: read (r) - the user can read the contents of the file, or the user can just read file names in the case of a directory (or folder) write (w) - the user can modify the file, or the user can create or delete files in the case of a directory (or folder) execute (x) - the user can execute a file - this allows the operating system to run the file, for example a user could run a script, or the user can search among files in the case of a directory (or folder) Values for permission follow a standard form: The first value indicates information about the file type, if it is a regular file it is often just a -. This does not indicate any information about permissions. If it is a link to a file located somewhere else it is indicated with an l. The next 3 values indicate what the owner of the file can do. They are always listed in the order of read, write, and execute permissions. The next three values indicate what the group members can do (again with the order listed above). the final three values indicate what other users can do (again with the order listed above) (“File-System Permissions” 2021). Sometimes you will see an @ or + symbol at the end, which indicates that there are additional attributes about the file that you can use a command like ls-al@ filename to get the information, or additional security information about the file, which you can obtain using a command like ls -le filename or getfacl filename. The command that you should use depends on your operating system. In the above image we see -rwxr-xr-x for one of the files. The - at the beginning indicates that the file is a regular file, the next 3 values of rwx indicate that the owner has read, write, and execute permissions, the r-x indicates that the group has read and execute permissions but not write, and the last r-x indicate that the other users also have only read and execute permissions. There are commands to modify file permissions. If you are using a Unix-like system, you can modify permissions with the chmod command, which stands for “change mode” (“Manage File Permissions on Unix-Like Systems” n.d.). 2.2.3.1 The principal of least privilege The principal of least privilege (PoLP) also called the principal of least authority specifies that users should only have access to the data or resources necessary to complete a task. If someone does not need access to perform work, they should not be given access. Furthermore, if someone is given access to perform a task and they complete that task, access should then be removed from that person. Additionally, if someone only needs to read a file, then they do not need access to modify the file. In this case a user can have read permissions but not write permissions. Ultimately this type of management leads to the least number of users having access to read or alter protected or sensitive data at a given time (“Least Privilege CISA” n.d.; “Wikipedia: Principle of Least Privilege” 2021). As an example of this in practice: If a postdoc is working on a project with sensitive data, and the PI does not need to see the raw data to collaborate on the project, then the PI should not have access to the data. 2.2.4 WiFi 2.2.5 Passwords 2.2.6 Stale access 2.2.7 Flash drives.. not sure where to put this… 2.3 Data masking Encryption is actually just one of the more complex methods of a larger concept called data masking for protecting sensitive data. There are other methods for obscuring parts of the data besides the complexity of encryption, such as the following: 2.3.1 De-identification https://www.hhs.gov/hipaa/for-professionals/privacy/special-topics/de-identification/index.html https://opin.com/de-identify-health-information-phi-v2/ https://en.wikipedia.org/wiki/De-identification #### Safe harbor #### Expert Determination #### Limitations 2.3.2 Encryption Encryption is one of the most well-known methods for keeping data safe. It is used as a last method in case unauthorized users can access to data, and it is also used to protect data when transferring it. The process involves encoding or scrambling the data in a nonrandom format (we call this form of the data encrypted) that given the right instructions, a computer can reformat into the original form in a process called decryption. The instructions called the key are kept safe like a password and depending on the type of encryption, it can require quite a lot of computational power to decrypt the data. This protects the data because if a cybercriminal accesses the data or if the data is somehow made public when it shouldn’t be, it will not be easily interpreted (“What Is Data Encryption?” 2018). There are different methods for encrypting data. One common method is called asymmetric, which involves two keys, a public key and a private key (“What Is Encryption? Data Encryption Defined” n.d.). This method is also sometimes simply called public key. Users can get access to the public key to allow them to encrypt the data, while the private key remains private and is used to decrypt the data. This method is also called public-key encryption (“What Is Encryption? Data Encryption Defined” n.d.). Symmetric cryptography on the other hand uses one key for encryption and decryption. In systems that use this type of encryption, pairs of users will often be given their own key. The advantage of this system is that decryption is a bit faster, the keys are smaller, and it is generally less expensive to implement. If someone gains access to the key, however they can decrypt data or messages, and encrypt data or messages and appear as if they are the person that owns that key. So often the keys themselves are encrypted (“What Is Encryption? Data Encryption Defined” n.d.). Since symmetric decryption is faster, it is often used for transferring data or for large datasets.Common symmetric algorithms are AES-128, AES-192, and AES-256 (Labs n.d.). Asymmetric encryption is regarded to be more secure, common algorithms included RSA and DSA, and several PKCS standards (Labs n.d.). These algorithms involve mathematical operations to encrypt the data. See this video for a simplified explanation and a suggestion for a video series if you want to learn more about how these encryption algorithms work: 2.3.2.1 SSL Socket Layer This is what the s in https is for. This indicates that data from the server is using a form of encryption and that the website server has a special SSL certificate from a trusted Certificate Authority that verified that the server can be trusted. There is actually a lot happening behind the scenes! According to “What Is SSL (Secure Sockets Layer)? What Is an SSL Certificate? DigiCert” (n.d.) this involves the following steps: A web browser (like chrome) connects to a web server (website) that is secured with SSL (it starts with https instead of http). The browser asks the server to identify itself. The Server sends a copy of the SSL certificate and the public key. The browser checks the certificate to make sure that it comes from a trusted certificate authority and that the certificate has not expired or been revoked. The browser also checks that the names on the certificate and the website match. It then sends the server an encrypted session key based on the public key. The server then decrypts the session key using the private key and sends an encrypted acknowledgment to start an encrypted session. The server and browser can now transmit encrypted data back and forth. Note that newer versions of this process are called Transport Layer Security (TLS). 2.3.2.2 SSH Secure Shell SSH is also a process for securely transmitting files from one computer to another using encryption. However, in this case it can be done using a command line interface instead of a browser. SSH also does not involve certificate. https://sectigostore.com/blog/ssh-vs-ssl-exploring-the-similarities-and-differences/ https://www.jscape.com/blog/ssl-vs-ssh-simplified 2.4 Data erasure It turns out that when you delete a file (even after emptying the trash), it isn’t as “deleted” as you might think. This is because when a file is deleted, the data for that file actually stays on the storage hardware, and it’s simply the computer’s ability to find the data that is hindered. However, there is software that can help people recover data on storage hardware. This can be a great security issue, as sensitive data can remain on people’s hardware when they get a new computer or stop using particular data on a server. One method to ensure that the deleted data is really eliminated is to physically destroy the hardware that it was stored on. However, this isn’t always necessary, as there are methods using software. This option is great because the hardware can be reused without allowing future users potential access to your data. As you might imagine, this is the preferred method for erasing data on shared computing resources like servers (Tilly Holland 2020). These methods erase the data by overwriting the data with random digital information (“Data Erasure” 2021). 2.5 Data resiliency 2.6 Security in workflows References "],["data-privacy.html", "Chapter 3 Data Privacy", " Chapter 3 Data Privacy Cancer research often involves personal health data that requires compliance with Health Insurance Portability and Accountability Act (HIPAA) regulations. In this chapter we will discuss data management strategies to maintain compliance with these important regulations. "],["data-sharing.html", "Chapter 4 Data Sharing 4.1 Data sharing is important! 4.2 Data repositories 4.3 Data Submission tips", " Chapter 4 Data Sharing In this chapter we will discuss the importance of data sharing, best practices for data sharing, places where you can store your data, as well as methods to share data in contexts in which you might have thought sharing was not possible! 4.1 Data sharing is important! Sharing data is critical for optimizing the advancement of scientific understanding. Now that labs all over the world are producing massive amounts of data, there are many discoveries that can be made by just using this existing data. This is so important, that starting in January, 2023 the NIH will require specific sharing practices for data management and sharing. See the announcement here. There’s so many excellent reasons to put your data in a repository whether or not a journal requires it: Sharing your data… Makes your project more transparent and thus more likely to be trusted and cited. {r, fig.align='center', echo = FALSE, fig.alt= \"Another researcher is downloading the data from a repository and says ‘These insights are so exciting! I can’t wait to look into this data even more!’ \", out.width=\"100%\"} ottrpal::include_slide(\"https://docs.google.com/presentation/d/1SRokLaGAc2hiwJSN26FHE0ZEEhPr3KQdyMICic8kAcs/edit#slide=id.g117c57cc481_0_636\") Helps your relieve your own workload so your email inbox isn’t loaded by requests you probably don’t have time to respond to. Allows others to gain even more insights from your data which shows funders that your data will be used to its maximum potential. 4.2 Data repositories The best way to share your data is by putting it somewhere that others can download it (and it can be kept private when necessary). There’s many repositories out there that handle this for you. Below are some of the standard repositories for data you should consider. For a longer list of repositories, we also advise consulting this Nature guidance on data repositories. 4.2.1 Genomic Data Repositories National Center for Biotechnology Information (NCBI) For microarray: GEO Gene Expression Omnibus (GEO) For RNA-seq: SRA (Sequencing Read Archive) European Molecular Biology Laboratory-European Bioinformatics Institute (EMBL-EBI) International Nucleotide Sequence Databases—DNA Data Bank of Japan (DDBJ) 4.2.2 Imaging data repositories Imaging data resource Cancer imaging archive 4.2.3 Repositories for journal articles For manuscripts or large datasets that are of atypical format, using one of these repositories is a good idea. The journal you submit to may have a recommendation of one over another. If not, you might end up having a preference. CyVerse Data Commons Repository Data Dryad FigShare ZENODO 4.2.4 Small datasets Data sets that are small and atypical format can be published as supplementary files as a part of a manuscript. 4.3 Data Submission tips Uploading a dataset to a data repository is a great step toward sharing your data! But, the dataset uploaded is unclear and unusable it might as well not been uploaded in the first place. Keep in mind that although you may understand the ins and outs of your dataset and project, its likely that others who look at your data will not understand your notation. To make your data truly shared, you need to take the time to make sure it is well-organized and well-described! There are two files you should make sure to include to help describe and organize your data project: A main README file that orients others to what is included in your data. A metadata file that samples that are included, how they are connected, and when appropriate following privacy ethics, describes clinical features. Standards for genomic metadata 4.3.1 Use consistent and clear names Make sure that sample and data IDs used are consistent across the project - make sure to include a metadata file that describes in detail your samples in a way that is clear without any prior knowledge of the project. Sample and data IDs should keep with standard formatting otherwise known in the field. Features names should avoid using genomic coordinates as these may change with new genome versions. 4.3.2 Make your project reproducible Reproducible projects are able to be re-run by others to obtain the same results. The main requirements for a reproducible project are: The data can be freely obtained from a repository (this maybe summarized data for the purposes of data privacy). The code can be freely obtained from GitHub (or another similar repository). The software versions used to obtain the results are made clear by documentation or providing a Docker container. The code and data are well described and organized with a system that is consistent. 4.3.3 Have someone else review your code and data! The best way to find out if your data are useable by others is to have someone else look it over! There are so many little details that go into your data and projects. Those details can easily lead to typos and errors upon data submission and also can lead to confusion when others (or your future self) are attempting to use that data.The best way to test if your data project is useable is to have someone else (who has not prepared the data) is able to make sense of it. For more details on how to make data and code reproducible tips, see our Intro to Reproducibility course. "],["data-ethics.html", "Chapter 5 Data Ethics", " Chapter 5 Data Ethics Now that we have covered the basics of data management, we will take a moment to consider and reflect on the implications of our use and sharing of data. "],["about-the-authors.html", "About the Authors", " About the Authors These credits are based on our course contributors table guidelines.     In memory of James Taylor, who was instrumental in initiating this project.   These are currently from another course … will update later Credits Names Pedagogy Lead Content Instructor Carrie Wright Content Editors/Reviewers Candace Savonen, Sarah Wheelan, Jeff Leek Content Directors Jeff Leek, Sarah Wheelan Content Consultants (Shared computing etiquette) Brian Caffo, Mark Miller Acknowledgments Anne Carpenter, Luis Pedro Coelho Production Content Publisher Ira Gooding Content Publishing Reviewers Ira Gooding, Candace Savonen Technical Course Publishing Engineer Carrie Wright Template Publishing Engineers Candace Savonen, Carrie Wright Publishing Maintenance Engineer Candace Savonen Technical Publishing Stylists Carrie Wright, Candace Savonen Package Developers (ottrpal) John Muschelli, Candace Savonen, Carrie Wright Art and Design Illustrator Carrie Wright Funding Funder National Cancer Institute (NCI) UE5 CA254170 Funding Staff Emily Voeglein, Fallon Bachman   ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.0.2 (2020-06-22) ## os Ubuntu 20.04.3 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Etc/UTC ## date 2022-03-03 ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date lib source ## assertthat 0.2.1 2019-03-21 [1] RSPM (R 4.0.3) ## bookdown 0.24 2022-02-15 [1] Github (rstudio/bookdown@88bc4ea) ## callr 3.4.4 2020-09-07 [1] RSPM (R 4.0.2) ## cli 2.0.2 2020-02-28 [1] RSPM (R 4.0.0) ## crayon 1.3.4 2017-09-16 [1] RSPM (R 4.0.0) ## desc 1.2.0 2018-05-01 [1] RSPM (R 4.0.3) ## devtools 2.3.2 2020-09-18 [1] RSPM (R 4.0.3) ## digest 0.6.25 2020-02-23 [1] RSPM (R 4.0.0) ## ellipsis 0.3.1 2020-05-15 [1] RSPM (R 4.0.3) ## evaluate 0.14 2019-05-28 [1] RSPM (R 4.0.3) ## fansi 0.4.1 2020-01-08 [1] RSPM (R 4.0.0) ## fs 1.5.0 2020-07-31 [1] RSPM (R 4.0.3) ## glue 1.6.1 2022-01-22 [1] CRAN (R 4.0.2) ## htmltools 0.5.0 2020-06-16 [1] RSPM (R 4.0.1) ## jquerylib 0.1.4 2021-04-26 [1] CRAN (R 4.0.2) ## knitr 1.33 2022-02-15 [1] Github (yihui/knitr@a1052d1) ## lifecycle 1.0.0 2021-02-15 [1] CRAN (R 4.0.2) ## magrittr 2.0.2 2022-01-26 [1] CRAN (R 4.0.2) ## memoise 1.1.0 2017-04-21 [1] RSPM (R 4.0.0) ## pkgbuild 1.1.0 2020-07-13 [1] RSPM (R 4.0.2) ## pkgload 1.1.0 2020-05-29 [1] RSPM (R 4.0.3) ## prettyunits 1.1.1 2020-01-24 [1] RSPM (R 4.0.3) ## processx 3.4.4 2020-09-03 [1] RSPM (R 4.0.2) ## ps 1.3.4 2020-08-11 [1] RSPM (R 4.0.2) ## purrr 0.3.4 2020-04-17 [1] RSPM (R 4.0.3) ## R6 2.4.1 2019-11-12 [1] RSPM (R 4.0.0) ## remotes 2.2.0 2020-07-21 [1] RSPM (R 4.0.3) ## rlang 0.4.10 2022-02-15 [1] Github (r-lib/rlang@f0c9be5) ## rmarkdown 2.10 2022-02-15 [1] Github (rstudio/rmarkdown@02d3c25) ## rprojroot 2.0.2 2020-11-15 [1] CRAN (R 4.0.2) ## sessioninfo 1.1.1 2018-11-05 [1] RSPM (R 4.0.3) ## stringi 1.5.3 2020-09-09 [1] RSPM (R 4.0.3) ## stringr 1.4.0 2019-02-10 [1] RSPM (R 4.0.3) ## testthat 3.0.1 2022-02-15 [1] Github (R-lib/testthat@e99155a) ## usethis 2.1.5.9000 2022-02-15 [1] Github (r-lib/usethis@57b109a) ## withr 2.3.0 2020-09-22 [1] RSPM (R 4.0.2) ## xfun 0.26 2022-02-15 [1] Github (yihui/xfun@74c2a66) ## yaml 2.2.1 2020-02-01 [1] RSPM (R 4.0.3) ## ## [1] /usr/local/lib/R/site-library ## [2] /usr/local/lib/R/library "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
